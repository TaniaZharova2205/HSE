{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TaniaZharova2205/HSE/blob/main/Python_1_2/DZ3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. **Сравнение подходов для синхронизации потоков (1б)**\n",
        "\n",
        "Напишите программу, которая моделирует доступ к общему ресурсу из пяти потоков. Каждый поток должен:\n",
        "\n",
        "1. Заблокировать доступ к ресурсу.\n",
        "2. Печатать сообщение о начале работы.\n",
        "3. \"Использовать\" ресурс (симулируйте это с помощью `time.sleep(1)`).\n",
        "4. Печатать сообщение об окончании работы и освобождать ресурс.\n",
        "\n",
        "Сравните два подхода к синхронизации:\n",
        "\n",
        "1. Используя `threading.Lock`.\n",
        "2. Используя `threading.Semaphore`, где одновременно доступ к ресурсу могут иметь два потока."
      ],
      "metadata": {
        "id": "bJeW_-J6au8R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import threading\n",
        "import time\n",
        "\n",
        "\n",
        "def access_resource_with_lock(lock, thread_id):\n",
        "    with lock:\n",
        "        print(f\"Поток {thread_id} начал работу.\")\n",
        "        time.sleep(1)\n",
        "        print(f\"Поток {thread_id} завершил работу.\")\n",
        "\n",
        "\n",
        "def access_resource_with_semaphore(semaphore, thread_id):\n",
        "    with semaphore:\n",
        "        print(f\"Поток {thread_id} начал работу.\")\n",
        "        time.sleep(1)\n",
        "        print(f\"Поток {thread_id} завершил работу.\")\n",
        "\n",
        "\n",
        "def main():\n",
        "    # Синхронизация с Lock\n",
        "    print(\"С lock:\")\n",
        "    lock = threading.Lock()\n",
        "    threads = []\n",
        "    for i in range(5):\n",
        "        thread = threading.Thread(target=access_resource_with_lock, args=(lock, i))\n",
        "        threads.append(thread)\n",
        "        thread.start()\n",
        "\n",
        "    for thread in threads:\n",
        "        thread.join()\n",
        "\n",
        "    # Синхронизация с Semaphore\n",
        "    print(\"\\n С semaphore:\")\n",
        "    semaphore = threading.Semaphore(2)\n",
        "    threads = []\n",
        "    for i in range(5):\n",
        "        thread = threading.Thread(target=access_resource_with_semaphore, args=(semaphore, i))\n",
        "        threads.append(thread)\n",
        "        thread.start()\n",
        "\n",
        "    for thread in threads:\n",
        "        thread.join()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xLTiBQhy7S7j",
        "outputId": "9a5b57d9-3b4c-4017-ec62-cd471df24e59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "С lock:\n",
            "Поток 0 начал работу.\n",
            "Поток 0 завершил работу.\n",
            "Поток 1 начал работу.\n",
            "Поток 1 завершил работу.\n",
            "Поток 2 начал работу.\n",
            "Поток 2 завершил работу.\n",
            "Поток 3 начал работу.\n",
            "Поток 3 завершил работу.\n",
            "Поток 4 начал работу.\n",
            "Поток 4 завершил работу.\n",
            "\n",
            " С semaphore:\n",
            "Поток 0 начал работу.\n",
            "Поток 1 начал работу.\n",
            "Поток 0 завершил работу.\n",
            "Поток 2 начал работу.\n",
            "Поток 1 завершил работу.\n",
            "Поток 3 начал работу.\n",
            "Поток 2 завершил работу.\n",
            "Поток 4 начал работу.\n",
            "Поток 3 завершил работу.\n",
            "Поток 4 завершил работу.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. **Очередь задач с задержкой на потоках (2б)**\n",
        "\n",
        "Реализуйте систему обработки задач с очередью `queue.PriorityQueue`. Программа должна состоять из:\n",
        "\n",
        "1. **Производителя** (`producer`): добавляет задачи с приоритетами от 1 до 5 (1 — самый высокий) в очередь с интервалом 0.5 секунды.\n",
        "2. **Потребителя** (`consumer`): извлекает задачи из очереди в порядке приоритета и обрабатывает их (задержка 1 секунда на задачу).\n",
        "\n",
        "Если потребитель не получает новую задачу за 2 секунды, он завершает выполнение."
      ],
      "metadata": {
        "id": "bRPX1eUH7TL7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from queue import PriorityQueue\n",
        "import threading\n",
        "import time\n",
        "\n",
        "def producer(queue):\n",
        "    for i in range(5, 0, -1): # Добавление задачи с такими приоритетами в очередь в такой последовательности\n",
        "        print(f\"Добавлена задача с приоритетом {i}\")\n",
        "        time.sleep(0.5)\n",
        "        queue.put(i)\n",
        "\n",
        "def consumer(queue):\n",
        "    while True:\n",
        "          try:\n",
        "              item = queue.get(timeout=2)\n",
        "          except Exception:\n",
        "              print(\"Очередь пуста, завершение.\")\n",
        "              break\n",
        "          else:\n",
        "              print(f\"Обработка Задача с приоритетом {item}\")\n",
        "              time.sleep(1)\n",
        "              queue.task_done()\n",
        "\n",
        "def main():\n",
        "    queue = PriorityQueue()\n",
        "\n",
        "    producer_thread = threading.Thread(target=producer, args=(queue,))\n",
        "    producer_thread.start()\n",
        "\n",
        "    consumer_thread = threading.Thread(target=consumer, args=(queue,))\n",
        "    consumer_thread.start()\n",
        "\n",
        "    producer_thread.join()\n",
        "    consumer_thread.join()\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2uA5Luv27VDq",
        "outputId": "fcedca90-0821-41d0-a76a-c4bcb8a15ba5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Добавлена задача с приоритетом 5\n",
            "Добавлена задача с приоритетом 4Обработка Задача с приоритетом 5\n",
            "\n",
            "Добавлена задача с приоритетом 3\n",
            "Добавлена задача с приоритетом 2\n",
            "Обработка Задача с приоритетом 3\n",
            "Добавлена задача с приоритетом 1\n",
            "Обработка Задача с приоритетом 1\n",
            "Обработка Задача с приоритетом 2\n",
            "Обработка Задача с приоритетом 4\n",
            "Очередь пуста, завершение.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. **Ускорение обработки данных с помощью `ProcessPoolExecutor` / `multiprocessing.Pool` / `modin`  (2б)**\n",
        "\n",
        "Напишите программу, которая читает большой CSV-файл с колонками `col1` и `col2`. Используйте `ProcessPoolExecutor` для выполнения следующих операций:\n",
        "\n",
        "1. Для каждой строки вычислить результат: $ \\text{result} = \\text{col1}^2 + 2 \\cdot \\text{col2} $.\n",
        "2. Записать результаты обратно в новый CSV-файл.\n",
        "\n",
        "Добавьте измерение времени выполнения.\n"
      ],
      "metadata": {
        "id": "SOHgZFtB7VSn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install \"modin[dask]\""
      ],
      "metadata": {
        "id": "haTokvRWJVeq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from concurrent.futures import ProcessPoolExecutor\n",
        "from multiprocessing import Pool\n",
        "import time\n",
        "\n",
        "\n",
        "def process_row(row):\n",
        "    row['result'] = row['col1']**2 + 2 * row['col2']\n",
        "    return row\n",
        "\n",
        "def process_with_process_pool_executor(input_file, output_file, row_size, pool_size):\n",
        "    print(f\"=== ProcessPoolExecutor с чанком {row_size} ===\")\n",
        "    start_time = time.time()\n",
        "    rows = pd.read_csv(input_file, chunksize=row_size)\n",
        "\n",
        "    results = []\n",
        "    with ProcessPoolExecutor(max_workers=pool_size) as executor:\n",
        "        futures = [executor.submit(process_row, chunk) for chunk in rows]\n",
        "        results = [future.result() for future in futures]\n",
        "\n",
        "    final_df = pd.concat(results)\n",
        "    final_df.to_csv(output_file, index=False)\n",
        "\n",
        "    end_time = time.time()\n",
        "    print(f\"ProcessPoolExecutor завершено за {end_time - start_time:.2f} секунд.\\n\")\n",
        "\n",
        "def process_with_multiprocessing_pool(input_file, output_file, row_size, pool_size):\n",
        "    print(f\"=== multiprocessing.Pool с чанком {row_size} ===\")\n",
        "    start_time = time.time()\n",
        "    rows = pd.read_csv(input_file, chunksize=row_size)\n",
        "\n",
        "    results = []\n",
        "    with Pool(processes=pool_size) as pool:\n",
        "        results = pool.map(process_row, rows)\n",
        "\n",
        "    final_df = pd.concat(results)\n",
        "    final_df.to_csv(output_file, index=False)\n",
        "\n",
        "    end_time = time.time()\n",
        "    print(f\"multiprocessing.Pool завершено за {end_time - start_time:.2f} секунд.\\n\")\n",
        "\n",
        "def process_modin(input_file, output_file):\n",
        "    print(f\"=== Обычная обработка с Pandas ===\")\n",
        "    start_time = time.time()\n",
        "    df = pd.read_csv(input_file)\n",
        "    df['result'] = df['col1']**2 + 2 * df['col2']\n",
        "    df.to_csv(output_file, index=False)\n",
        "    end_time = time.time()\n",
        "    print(f\"Pandas завершено за {end_time - start_time:.2f} секунд.\\n\")\n",
        "\n",
        "def main():\n",
        "    input_file = 'large_file.csv'\n",
        "    output_file_executor = 'processed_file_executor.csv'\n",
        "    output_file_modin = 'processed_file_modin.csv'\n",
        "    output_file_pool = 'processed_file_pool.csv'\n",
        "    df = pd.DataFrame({\n",
        "        'col1': range(1, 1000001),\n",
        "        'col2': range(1000000, 0, -1)\n",
        "    })\n",
        "    df.to_csv(input_file, index=False)\n",
        "    for row_size in [25000, 200000, 500000]:\n",
        "        process_with_process_pool_executor(input_file, output_file_executor, row_size, pool_size=4)\n",
        "        process_with_multiprocessing_pool(input_file, output_file_pool, row_size, pool_size=4)\n",
        "    process_modin(input_file, output_file_modin)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tD-t5Nph7Vqx",
        "outputId": "9ecc037a-dbb0-4c65-948d-f69455d0c28b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== ProcessPoolExecutor с чанком 25000 ===\n",
            "ProcessPoolExecutor завершено за 2.12 секунд.\n",
            "\n",
            "=== multiprocessing.Pool с чанком 25000 ===\n",
            "multiprocessing.Pool завершено за 2.16 секунд.\n",
            "\n",
            "=== ProcessPoolExecutor с чанком 200000 ===\n",
            "ProcessPoolExecutor завершено за 2.03 секунд.\n",
            "\n",
            "=== multiprocessing.Pool с чанком 200000 ===\n",
            "multiprocessing.Pool завершено за 3.67 секунд.\n",
            "\n",
            "=== ProcessPoolExecutor с чанком 500000 ===\n",
            "ProcessPoolExecutor завершено за 2.70 секунд.\n",
            "\n",
            "=== multiprocessing.Pool с чанком 500000 ===\n",
            "multiprocessing.Pool завершено за 2.39 секунд.\n",
            "\n",
            "=== Обычная обработка с Pandas ===\n",
            "Pandas завершено за 3.06 секунд.\n",
            "\n"
          ]
        }
      ]
    }
  ]
}