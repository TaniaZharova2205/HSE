{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pdr12C7SpZsn"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "np.sqrt(2 / np.pi)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pETGPk2jxJ4I",
    "outputId": "bd828107-8d06-4e54-8388-27f3eeefd60c"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "np.float64(0.7978845608028654)"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "def gen_batch(batch_size):\n",
    "    return torch.randn(batch_size, 1024), torch.zeros(batch_size).to(torch.long)"
   ],
   "metadata": {
    "id": "68Au0AcDwcPF"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "class GELU(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return 0.5 * x * (1 + torch.tanh(0.79788 * (x + 0.044715 * torch.pow(x, 3))))"
   ],
   "metadata": {
    "id": "N1a5XxA4w0g6"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "hidden = 4096\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(1024, hidden),\n",
    "    GELU(),\n",
    "    nn.Linear(hidden, hidden),\n",
    "    GELU(),\n",
    "    nn.Linear(hidden, hidden),\n",
    "    GELU(),\n",
    "    nn.Linear(hidden, hidden),\n",
    "    GELU(),\n",
    "    nn.Linear(hidden, hidden),\n",
    "    GELU(),\n",
    "    nn.Linear(hidden, hidden),\n",
    "    GELU(),\n",
    "    nn.Linear(hidden, hidden),\n",
    "    GELU(),\n",
    "    nn.Linear(hidden, hidden),\n",
    "    GELU(),\n",
    "    nn.Linear(hidden, hidden),\n",
    "    GELU(),\n",
    "    nn.Linear(hidden, hidden),\n",
    "    GELU(),\n",
    "    nn.Linear(hidden, hidden),\n",
    "    GELU(),\n",
    "    nn.Linear(hidden, hidden),\n",
    "    GELU(),\n",
    "    nn.Linear(hidden, hidden),\n",
    "    GELU(),\n",
    "    nn.Linear(hidden, hidden),\n",
    "    GELU(),\n",
    "    nn.Linear(hidden, hidden),\n",
    "    GELU(),\n",
    "    nn.Linear(hidden, hidden),\n",
    "    GELU(),\n",
    "    nn.Linear(hidden, 32768),\n",
    ")"
   ],
   "metadata": {
    "id": "mBDDoufJxZ5f"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# model = torch.compile(model)\n",
    "model.to(\"cuda\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Aa-PK3w0zrZD",
    "outputId": "8cc1843c-7ca3-43d6-9bae-f5b3d4953c56"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "  (1): GELU()\n",
       "  (2): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "  (3): GELU()\n",
       "  (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "  (5): GELU()\n",
       "  (6): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "  (7): GELU()\n",
       "  (8): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "  (9): GELU()\n",
       "  (10): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "  (11): GELU()\n",
       "  (12): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "  (13): GELU()\n",
       "  (14): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "  (15): GELU()\n",
       "  (16): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "  (17): GELU()\n",
       "  (18): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "  (19): GELU()\n",
       "  (20): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "  (21): GELU()\n",
       "  (22): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "  (23): GELU()\n",
       "  (24): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "  (25): GELU()\n",
       "  (26): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "  (27): GELU()\n",
       "  (28): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "  (29): GELU()\n",
       "  (30): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "  (31): GELU()\n",
       "  (32): Linear(in_features=4096, out_features=32763, bias=True)\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "torch.set_float32_matmul_precision(\"medium\")\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), fused=True)\n",
    "\n",
    "for i in range(32):\n",
    "    x, y = gen_batch(16)\n",
    "    t0 = time.time()\n",
    "    with torch.autocast(device_type=\"cuda\", dtype=torch.bfloat16):\n",
    "        x = x.to(\"cuda\", non_blocking=True)\n",
    "        y = y.to(\"cuda\", non_blocking=True)\n",
    "        loss = criterion(model(x), y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    torch.cuda.synchronize()\n",
    "    t1 = time.time()\n",
    "    print(np.round((t1 - t0) * 1000, 2))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bYJY474ezwXT",
    "outputId": "c8f27304-2391-4b15-d0aa-3bfc0fbbf703"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "268.73\n",
      "142.9\n",
      "143.51\n",
      "142.46\n",
      "141.6\n",
      "144.27\n",
      "142.87\n",
      "144.58\n",
      "144.17\n",
      "145.15\n",
      "143.4\n",
      "143.29\n",
      "142.78\n",
      "143.82\n",
      "141.56\n",
      "143.21\n",
      "143.9\n",
      "144.89\n",
      "144.65\n",
      "144.54\n",
      "144.3\n",
      "143.94\n",
      "144.34\n",
      "144.44\n",
      "146.49\n",
      "144.26\n",
      "144.25\n",
      "145.17\n",
      "145.15\n",
      "145.57\n",
      "144.69\n",
      "144.52\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "LuWdfxWz0yXB"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}